{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c2bf5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io\n",
    "import shutil\n",
    "import os\n",
    "from scipy.io.wavfile import write\n",
    "from scipy.signal import resample\n",
    "import csv\n",
    "\n",
    "from parameters_CINC11CINC17_unbalanced import parameters\n",
    "# from parameters_CINC11CINC17_unbalanced import parameters\n",
    "from data_storage_utils import create_directory, normalizer, generate_store_kramer_data\n",
    "\n",
    "parameters = parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7646692",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "615887a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_training_data = parameters['annotation_file_train'] # location of anntotation file\n",
    "path_testing_data =  parameters['annotation_file_test'] # location of anntotation file\n",
    "path_cinc11 = parameters['path_cinc11']\n",
    "path_cinc17 = parameters['path_cinc17']\n",
    "path_save = parameters['path_training_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a109b35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_length = parameters['data_length']\n",
    "data_length_cinc17_300hz = parameters['data_length_cinc17_300hz']\n",
    "wav_data_range = parameters['wav_data_range']\n",
    "amount_data = parameters['amount_data'] # number of datapoints we want per label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "573fdeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_count = [0, 0] # nubmer of current datapoints per label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "862445eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only for debugging, remove existing dataset by removing folder:\n",
    "# shutil.rmtree(path_save+\"\\\\0\")\n",
    "# shutil.rmtree(path_save+\"\\\\1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dff8da3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the folders for storing the data\n",
    "\n",
    "# def create_directory(output_path):\n",
    "#     \"\"\"\n",
    "#     output_path: the path from source to the output folder \n",
    "    \n",
    "#     creates the folders needed to store the output data\n",
    "#     \"\"\"\n",
    "#     if not os.path.exists(output_path):\n",
    "#         os.makedirs(output_path)\n",
    "#     if not os.path.exists(output_path+'/0'):\n",
    "#         os.makedirs(output_path+'/0')\n",
    "#     if not os.path.exists(output_path+'/1'):\n",
    "#         os.makedirs(output_path+'/1')\n",
    "#     if not os.path.exists(output_path+'/rest'):\n",
    "#         os.makedirs(output_path+'/rest')\n",
    "        \n",
    "#         print('output directories created')\n",
    "\n",
    "# create_directory(path_save)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f92b3f",
   "metadata": {},
   "source": [
    "Normalization function used:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf8a1b7",
   "metadata": {},
   "source": [
    "$data_{normalized}\\mapsto \\frac{data-r_{\\text{min}}}{r_{\\text{max}}-r_{\\text{min}}}\\times (t_{\\text{max}}-t_{\\text{min}}) + t_{\\text{min}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9508910c",
   "metadata": {},
   "source": [
    "Get the annotation of the data and save it in the `annotations` array and their corresponding recording numbers and save it in the `recording numbers` array. The `generate_store_kramer_data` function finds the location where the data is stored. The name of the data file is the recording number. The data is then saved as a `.wav` file in a folder named according to the annotation number. E.G. : `\\\\Code\\\\kramer_data\\\\0\\\\1002603_10.wav`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "facc796f",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = []\n",
    "\n",
    "with open(path_training_data+\"\\\\Annotation Training Set Group I.txt\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines: \n",
    "        line = line.split('\\t')\n",
    "        annotations_12 = []\n",
    "        for val in line: \n",
    "            annotations_12.append(val[0])\n",
    "        annotations.append(annotations_12)\n",
    "        \n",
    "recording_numbers = []\n",
    "\n",
    "with open(path_training_data+\"\\\\Training 50 Group I recording names.txt\") as f:\n",
    "    line = f.readline() \n",
    "    line = line.split('\\t')\n",
    "    for val in line: \n",
    "        val = val.split('\\n')\n",
    "        recording_numbers.append(val[0])\n",
    "        \n",
    "label_count = generate_store_kramer_data(annotations, recording_numbers, wav_data_range, label_count, path_cinc11, path_save, amount_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad596614",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = []\n",
    "\n",
    "with open(path_training_data+\"\\\\Annotation Training Set Group II.txt\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines: \n",
    "        line = line.split('\\t')\n",
    "        annotations_12 = []\n",
    "        for val in line: \n",
    "            annotations_12.append(val[0])\n",
    "        annotations.append(annotations_12)\n",
    "        \n",
    "recording_numbers = []\n",
    "\n",
    "with open(path_training_data+\"\\\\Training 50 Group II recording names.txt\") as f:\n",
    "    line = f.readline() \n",
    "    line = line.split('\\t')\n",
    "    for val in line: \n",
    "        val = val.split('\\n')\n",
    "        recording_numbers.append(val[0])\n",
    "        \n",
    "label_count = generate_store_kramer_data(annotations, recording_numbers, wav_data_range, label_count, path_cinc11, path_save, amount_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5d09efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = []\n",
    "\n",
    "with open(path_testing_data+\"\\\\Annotation Testing Set Group I.txt\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines: \n",
    "        line = line.split('\\t')\n",
    "        annotations_12 = []\n",
    "        for val in line: \n",
    "            annotations_12.append(val[0])\n",
    "        annotations.append(annotations_12)  \n",
    "\n",
    "recording_numbers = []\n",
    "\n",
    "with open(path_testing_data+\"\\\\Testing 175 Group I recording names.txt\") as f:\n",
    "    lines = f.readlines() \n",
    "    for val in lines:\n",
    "        val = val.split('\\n')\n",
    "        recording_numbers.append(val[0])\n",
    "\n",
    "# print(recording_numbers)\n",
    "label_count = generate_store_kramer_data(annotations, recording_numbers, wav_data_range, label_count, path_cinc11, path_save, amount_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d85abad4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "annotations = []\n",
    "\n",
    "with open(path_testing_data+\"\\\\Annotation Testing Set Group II.txt\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines: \n",
    "        line = line.split('\\t')\n",
    "        annotations_12 = []\n",
    "        for val in line: \n",
    "            annotations_12.append(val[0])\n",
    "        annotations.append(annotations_12)\n",
    "        \n",
    "recording_numbers = []\n",
    "\n",
    "with open(path_testing_data+\"\\\\Testing 175 Group II recording names.txt\") as f:\n",
    "    lines = f.readlines() \n",
    "    for val in lines:\n",
    "        val = val.split('\\n')\n",
    "        recording_numbers.append(val[0])\n",
    "        \n",
    "label_count = generate_store_kramer_data(annotations, recording_numbers, wav_data_range, label_count, path_cinc11, path_save, amount_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12c0ddeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commands: [0, 1]\n",
      "Amount CinC11 data per label: [284, 8244]\n"
     ]
    }
   ],
   "source": [
    "# save labels \n",
    "commands = [0, 1]\n",
    "commands_count = [0, 0]\n",
    "\n",
    "dict_labels = {}\n",
    "with open(path_cinc17+\"\\\\REFERENCE.csv\", mode='r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        if row[1] == '~':\n",
    "            dict_labels[f'{row[0]}'] = commands[0]\n",
    "            commands_count[0] += 1\n",
    "        else: \n",
    "            dict_labels[f'{row[0]}'] = commands[1]\n",
    "            commands_count[1] += 1\n",
    "print('Commands:', commands)\n",
    "print('Amount CinC11 data per label:', commands_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82cfee52",
   "metadata": {},
   "source": [
    "Top up the Kramer data with CINC17 data to get enough datapoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e8b6940e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(path_cinc17+\"\\\\training2017\\\\RECORDS\") as f:\n",
    "    lines = f.readlines()\n",
    "    file_names = []        \n",
    "\n",
    "    for i, record_nr in enumerate(lines): \n",
    "        data_path = path_cinc17+\"\\\\\"f\"{record_nr[0:6]}.mat\"\n",
    "        file_names.append(data_path)\n",
    "        \n",
    "        label = dict_labels[f'{record_nr[0:6]}']\n",
    "\n",
    "        data = scipy.io.loadmat(data_path)\n",
    "        data = data.get('val').flatten()\n",
    "        data = normalizer(data, wav_data_range)\n",
    "\n",
    "        if len(data) < data_length_cinc17_300hz:\n",
    "            pass\n",
    "        else: \n",
    "            if label_count[label] < amount_data:\n",
    "                if label == 0: # if noisy data \n",
    "                    data = data[:data_length_cinc17_300hz]                     \n",
    "                    resampled_data = resample(data, data_length)\n",
    "                    resampled_data = np.asarray(resampled_data, dtype=np.int16)\n",
    "                    write(path_save+\"\\\\\"f\"{label}\\\\{record_nr[0:6]}.wav\", 500, resampled_data)\n",
    "                    label_count[label] += 1\n",
    "                    \n",
    "                else: # if not noisy data \n",
    "                    data = data[:data_length_cinc17_300hz]\n",
    "                    resampled_data = resample(data, data_length)\n",
    "                    resampled_data = np.asarray(resampled_data, dtype=np.int16)\n",
    "                    write(path_save+\"\\\\\"f\"{label}\\\\{record_nr[0:6]}.wav\", 500, resampled_data)\n",
    "                    label_count[label] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f547011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024, 11888]\n"
     ]
    }
   ],
   "source": [
    "print(label_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d7444dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shutil.rmtree(path_save+\"\\\\rest\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
